{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/19 12:35:54 WARN Utils: Your hostname, certusr-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "22/07/19 12:35:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/07/19 12:35:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/07/19 12:35:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/07/19 12:35:59 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('solution_ex_16').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = './data'\n",
    "outputPath = './output_ex_16'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the content of the readings\n",
    "readingsRDD = spark.sparkContext.textFile(inputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1451606400,12.1',\n",
       " '1451606460,12.2',\n",
       " '1451606520,13.5',\n",
       " '1451606580,14.0',\n",
       " '1451606640,14.0',\n",
       " '1451606700,15.5',\n",
       " '1451606760,15.0']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readingsRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the elements of each window.\n",
    "# Each reading with start time t belongs to 3 windows with a window size equal to 3:\n",
    "# - The one starting at time t-120s\n",
    "# - The one starting at time t-60s\n",
    "# - The one starting at time t\n",
    "\n",
    "def windowElementsFunc(reading):\n",
    "    fields = reading.split(\",\")\n",
    "\n",
    "    # Time stamp of this reading\n",
    "    t = int(fields[0])\n",
    "    # Temperature\n",
    "    temperature = float(fields[1])\n",
    "    \n",
    "    # The current reading, associated with time stamp t,\n",
    "    # is part of the windows starting at time t, t-60s, t-120s\n",
    "    \n",
    "    # pairs is a list containing three pairs (window start timestamp, current reading) associated with\n",
    "    # the three windows containing this reading\n",
    "    pairs = []\n",
    "    \n",
    "    # Window starting at time t\n",
    "    # This reading is the first element of the window starting at time t\n",
    "    pairs.append((t, reading))\n",
    "    \n",
    "    # Window starting at time t-60\n",
    "    # This reading is the second element of that window starting at time t-60\n",
    "    pairs.append((t-60, reading))\n",
    "\n",
    "    # Window starting at time t-120\n",
    "    # This reading is the third element of that window starting at time t-120\n",
    "    pairs.append((t-120, reading))\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowsElementsRDD = readingsRDD.flatMap(windowElementsFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use groupByKey to generate one sequence for each time stamp\n",
    "timestampsWindowsRDD = windowsElementsRDD.groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1451606400, ['1451606400,12.1', '1451606460,12.2', '1451606520,13.5']),\n",
       " (1451606340, ['1451606400,12.1', '1451606460,12.2']),\n",
       " (1451606280, ['1451606400,12.1']),\n",
       " (1451606460, ['1451606460,12.2', '1451606520,13.5', '1451606580,14.0']),\n",
       " (1451606520, ['1451606520,13.5', '1451606580,14.0', '1451606640,14.0']),\n",
       " (1451606580, ['1451606580,14.0', '1451606640,14.0', '1451606700,15.5']),\n",
       " (1451606640, ['1451606640,14.0', '1451606700,15.5', '1451606760,15.0']),\n",
       " (1451606700, ['1451606700,15.5', '1451606760,15.0']),\n",
       " (1451606760, ['1451606760,15.0'])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestampsWindowsRDD.mapValues(lambda v: list(v)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used in the next transformation to select the windows with an incrasing temperature trend\n",
    "def increasingTrendFunc(pairInitialTimestampWindow):\n",
    "\n",
    "    # The key of the input pair is the intial timestamp of the current window\n",
    "    minTimestamp = pairInitialTimestampWindow[0]\n",
    "    \n",
    "    # Store the (at most) 3 elements of the window in a dictionary\n",
    "    # containing enties time stamp -> temperature\n",
    "    timestampTemp = {}\n",
    "\n",
    "    # pairInitialTimestampWindow[1] contains the elements of the current window\n",
    "    window = pairInitialTimestampWindow[1]\n",
    "    \n",
    "    \n",
    "    for timestampTemperature in window:\n",
    "        fields = timestampTemperature.split(\",\")\n",
    "        t = int(fields[0])\n",
    "        temperature = float(fields[1])\n",
    "        \n",
    "        timestampTemp[t] = temperature\n",
    "        \n",
    "    \n",
    "    # Check if the list contains three elements.\n",
    "    # If the number of elements is not equal to 3 the window is incomplete and must be discarded\n",
    "    if len(timestampTemp) != 3:\n",
    "        increasing = False\n",
    "    else:\n",
    "        # Check is the increasing trend is satisfied\n",
    "        if timestampTemp[minTimestamp]<timestampTemp[minTimestamp+60] and timestampTemp[minTimestamp+60]<timestampTemp[minTimestamp+120]:\n",
    "            increasing = True\n",
    "        else:\n",
    "            increasing = False\n",
    "\n",
    "    return increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seletedWindowsRDD = timestampsWindowsRDD.filter(increasingTrendFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result is in the value part of the returned pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1451606400,12.1', '1451606460,12.2', '1451606520,13.5'],\n",
       " ['1451606460,12.2', '1451606520,13.5', '1451606580,14.0']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seletedWindowsRDD.values().map(lambda window: list(window)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the result. Map the iterable associated with each window to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seletedWindowsRDD.values().map(lambda window: list(window)).saveAsTextFile(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
